# Copyright (c) Meta Platforms, Inc. and affiliates.
# Adapted from: https://github.com/facebookresearch/swe-rl

import difflib
from typing import TypedDict

from unidiff import PatchSet
from unidiff.errors import UnidiffParseError


def generate_unified_diff(
    old_code: str,
    new_code: str,
    n_context: int = 3,
) -> str:
    """Generate a unified diff between two code.

    Args:
        old_code: The original code.
        new_code: The modified code.
        n_context: The number of context lines to show.

    Returns:
        A string representing the unified diff."""

    original_lines = old_code.splitlines()
    modified_lines = new_code.splitlines()

    diff = difflib.unified_diff(
        original_lines,
        modified_lines,
        fromfile="old",
        tofile="new",
        lineterm="",
        n=n_context,
    )
    try:
        next(diff)
        next(diff)
        diff_code = "\n".join(diff)
        return diff_code
    except StopIteration:
        return ""


class ChangeSimilarity(TypedDict):
    path: str
    pred_change: str
    oracle_change: str
    similarity: float


def compute_change_similarities(
    pred_patch: dict[str, str],
    oracle_patch: dict[str, str],
) -> list[ChangeSimilarity]:
    all_file_paths = set(oracle_patch.keys()).union(set(pred_patch.keys()))
    similarities = list[ChangeSimilarity]()
    for path in all_file_paths:
        pred_change = pred_patch.get(path, "")
        oracle_change = oracle_patch.get(path, "")
        if oracle_change == "" or pred_change == "":
            # Both are empty changes, meaning search = replace. We should penalize this to avoid
            # the model predicting empty changes to hack the reward.
            # NOTE: this should not happen due to (1) the search == replace check in `apply_code_change`
            # and (2) the `if patch` check in `get_normalized_patch`.
            change_similarity = 0.0
        else:
            change_similarity = difflib.SequenceMatcher(
                None,
                pred_change,
                oracle_change,
                autojunk=False,
            ).ratio()
        similarities.append(
            ChangeSimilarity(
                path=path,
                pred_change=pred_change,
                oracle_change=oracle_change,
                similarity=change_similarity,
            )
        )
    return similarities


def get_normalized_file_patch(patch_text: str) -> dict[str, str]:
    try:
        patch = PatchSet(patch_text)
    except (UnidiffParseError, UnboundLocalError):
        return {}
    result = dict[str, str]()
    for patchfile in patch:
        if patchfile.is_binary_file:
            # We don't consider binary files
            continue
        if patchfile.is_rename:
            # Add a special header for renamed files
            source_file = patchfile.source_file
            target_file = patchfile.target_file
            if source_file.startswith("a/"):
                source_file = source_file[2:]
            if target_file.startswith("b/"):
                target_file = target_file[2:]
            header = f"rename from {source_file} to {target_file}"
            path = source_file
        else:
            header = ""
            path = patchfile.path
        body = "\n".join(str(hunk).strip() for hunk in patchfile)
        content = header + "\n" + body
        content = content.strip()
        result[path] = content
    return result


def calculate_similarities_unidiff(
    oracle_patches: list[str],
    pred_patches: list[str],
    ignore_non_oracle_files: bool = False,
    both_empty_reward: float = 1.0,
) -> dict:
    """
    Compute the SWE-RL reward given two set of unified diffs.

    The return value is always within the range of [0, 1].

    Args:
        oracle_patches: A list of oracle diffs.
        pred_patches: A list of predicted diffs.

    Returns:
        A float value representing the reward, and a dictionary containing some metadata.
    """
    # Calculate the reward based on the similarity between the predicted and the oracle patch
    pred_patch_dict = dict[str, str]()
    oracle_patch_dict = dict[str, str]()

    for patch_text in oracle_patches:
        oracle_patch_dict.update(get_normalized_file_patch(patch_text))

    for patch_text in pred_patches:
        pred_patch_dict.update(get_normalized_file_patch(patch_text))

    if ignore_non_oracle_files:
        # Remove files that are not in the oracle patch
        pred_patch_dict = {
            fname: content
            for fname, content in pred_patch_dict.items()
            if fname in oracle_patch_dict
        }

    similarities = compute_change_similarities(pred_patch_dict, oracle_patch_dict)
    return dict(
        similarities=similarities,
        pred_patch_dict=pred_patch_dict,
        oracle_patch_dict=oracle_patch_dict,
    )
